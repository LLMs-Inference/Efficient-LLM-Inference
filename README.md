# Efficient-LLM-Inference

Efficient Inference for Large Language Models


## 🚀 课程

- [MIT Song Han | Model Compression and Acceleration Techniques for AI Computing](https://efficientml.ai/)

- [University of Pennsylvania | CIS 7000 - Large Language Models](https://llm-class.github.io/)

- [UC Berkeley & Google - Large Language Model Agents](https://llmagents-learning.org/f24)

- [California Institute of Technology - Large Language Models for Reasoning](https://sites.google.com/view/cs-159-2024)

- [CSE 561A: Large Language Models (2024 Fall)](https://teapot123.github.io/CSE561A_2024fl/)


## 🎮 视频教程

- [一小时精讲高性能 LLM 推理框架及细节优化](https://www.bilibili.com/video/BV1oT42117gL/)

- [Meta AI 的研究科学家 Kai Sheng Tai | 稀疏性促进高效 LLM 推理](https://www.youtube.com/watch?v=lIuHPxsgymU)

- [英伟达机器学习和深度学习专家 Christian Merkwirth | 优化 LLM 推理：挑战与最佳实践](https://www.youtube.com/watch?v=f7XcHUwQl4Y)

- [英伟达高级数据科学家 Mark Moyou | 从理论到具有成本效益的部署，掌握 LLM 推理优化](https://www.youtube.com/watch?v=9tvJ_GYJA-o)

- [NVIDIA GTC 技术干货 | 超大型 Transformer 模型的高效推理](https://www.nvidia.cn/on-demand/session/gtcspring23-s51088/)

- [硅谷知名华人 AI 科学家田渊栋 | 支持长文本上下文的 LLMs 的高效推理](https://www.youtube.com/watch?v=eXPhvQgAT_I)

- [Julien Simon 曾任亚马逊（AWS）人工智能和机器学习全球布道师 | 深度探究：LLM 推理优化](https://www.youtube.com/watch?v=hMs8VNRy5Ys)


## 🛞 开源项目

开源项目：

- [Easy, Fast, and Cheap LLM Serving for Everyone](https://github.com/vllm-project/vllm)

- [SGLang is a Fast Serving Framework for Large Language Models and Vision Language Models](https://github.com/sgl-project/sglang)

- [The Path to Open-Sourcing the DeepSeek Inference Engine](https://github.com/deepseek-ai/open-infra-index)


## 📝 博客

- [结合 MindIE-LLM 框架的具体优化案例，分析大模型推理加速的关键技术](https://mp.weixin.qq.com/s/3QYQDq4ZHQRwYMs6MmgVLg)

- [两万六千字，大模型核心技术综述：微调、推理与优化指南](https://mp.weixin.qq.com/s/TCG_dDhoUvtlmtcO_dwSgw)

- [大模型推理服务全景图](https://mp.weixin.qq.com/s/cDELflSEM7SV2Z3bupy65g)

- [Lilian Weng 出品，必是精品 | 大型 Transformer 模型推理优化](https://lilianweng.github.io/posts/2023-01-10-inference-optimization/)

- [高性能 LLM 推理框架的设计与实现](https://mp.weixin.qq.com/s/4o86rMuburB8jcbU0aYC7g)

- [AI 推理场景的痛点和解决方案](https://mp.weixin.qq.com/s/SeUJxNK10fhR6YsWSJRYwg)

- [Semi-PD，P/D 半分离的调度策略，大模型推理范式新选择](https://mp.weixin.qq.com/s/vQ5iXCXD7lJXogvT52PsLg)

- [一念 LLM 大语言模型推理加速](https://mp.weixin.qq.com/s/bmafuEaB3pfG72xEaPcR3g)

- [大模型的模型压缩与有效推理要点总结](https://mp.weixin.qq.com/s/8AltJXjXIZHvq7lPu8FKoQ)


## 💻 方法论文

- [Li, Y., Wei, F., Zhang, C., & Zhang, H. (2025). EAGLE-3: Scaling Up Inference Acceleration of Large Language Models via Training-Time Test. arXiv preprint arXiv: 2503.01840.](https://arxiv.org/abs/2503.01840)

- [Zhang, T., Sui, Y., Zhong, S., Chaudhary, V., Hu, X., & Shrivastava, A. (2025). 70% Size, 100% Accuracy: Lossless LLM Compression for Efficient GPU Inference via Dynamic-Length Float. arXiv preprint arXiv: 2504.11651.](https://arxiv.org/abs/2504.11651)


## 💡 综述论文

- [Zhen, R., Li, J., Ji, Y., Yang, Z., Liu, T., Xia, Q., ... & Zhang, M. (2025). Taming the Titans: A Survey of Efficient LLM Inference Serving. arXiv preprint arXiv: 2504.19720.](https://arxiv.org/abs/2504.19720)

- [Zhou, Z., Ning, X., Hong, K., Fu, T., Xu, J., Li, S., ... & Wang, Y. (2024). A Survey on Efficient Inference for Large Language Models. arXiv preprint arXiv: 2404.14294.](https://arxiv.org/abs/2404.14294)

- [Liu, Y., Wu, J., He, Y., Gao, H., Chen, H., Bi, B., ... & Hooi, B. (2025). Efficient Inference for Large Reasoning Models: A Survey. arXiv preprint arXiv: 2503.23077.](https://arxiv.org/abs/2503.23077)

- [Kim S, Hooper C, Wattanawong T, et al. Full Stack Optimization of Transformer Inference\[C\]//Architecture and System Support for Transformer Models (ASSYST@ ISCA 2023).](https://arxiv.org/abs/2302.14017)
